<img src="https://github.com/MEmilyGomes/BNN-em-Python-Puro/blob/main/Imagens/logo.png?raw=true" alt="Descri√ß√£o da imagem" style="width: 1000px; height: auto; ">

<h1 align="center">Rede Neural Bin√°ria (BNN) üóÉÔ∏è: </h1>

<h2 align="center">Predi√ß√£o da regi√£o do experimento de resson√¢ncia magn√©tica funcional (fMRI)</h2>

<p align="center"><strong>Autores:</strong> Maria Emily Nayla Gomes da Silva e Thomas Wolff Hannemann</p>
<p align="center"><strong>Professor:</strong> Daniel R. Cassar</p>


## üìù Introdu√ß√£o
<p align="justify">O trabalho apresenta a constru√ß√£o de uma <em>Rede Neural Bin√°ria</em> (BNN) com dados de fMRI, resson√¢ncia magn√©tica funcional. Por meio da linguagem de programa√ß√£o Python, sem o uso de bibliotecas que treinam modelos de aprendizado de m√°quina, foi desenvolvido um modelo de rede neural capaz de realizar uma classifica√ß√£o bin√°ria para predizer a regi√£o cerebral onde ocorreu o experimento de neuroimagem como "parietal" ou "frontal". Dessa forma, nosso trabalho consistiu em modificar uma Rede Neural de regress√£o ‚Äî algoritmo disponibilizado pelo Prof. Dr. Daniel Cassar ‚Äî para um modelo de classifica√ß√£o bin√°ria. Para isso, alteramos a fun√ß√£o de perda <em>Sum of Squared Errors (SSE)</em>, para <em>cross entropy</em> e adicionamos √† classe Valor o m√©todo de logaritmo natural. Al√©m disso, foram realizadas an√°lises de dados espec√≠ficas para o modelo de classifica√ß√£o bin√°ria.</p>

## üóÇÔ∏è Dataset seaborn fMRI
<p align="justify">O dataset utilizado para conseguir treinar a BNN foi o <strong>fmri</strong>, um dataset did√°tico da biblioteca Seaborn.<sup>1</sup> Os dados contidos nele s√£o sobre um experimento de neuroimagem funcional (<strong>fMRI</strong>), e cada coluna nos indica:</p>

### Tabela de Features do Dataset `fmri`

| Features    | Descri√ß√£o                                                                                                                                             |
|-------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
| `subject`   | C√≥digo identificador do participante.                                                                                                                 |
| `timepoint` | Ponto no tempo em que a medi√ß√£o foi realizada ‚Äì medida por TR (*repetition time*), que √© o intervalo entre duas aquisi√ß√µes consecutivas de imagens do c√©rebro. |
| `event`     | Tipo de est√≠mulo que o participante recebeu.                                                                                                          |
| `region`    | Regi√£o cerebral onde a medi√ß√£o foi feita.                                                                                                             |
| `signal`    | Valor do sinal fMRI medido na regi√£o ‚Äì a atividade cerebral registrada.                                                                               |

<p align="justify">Com esses dados dispon√≠veis, foram utilizadas como <em>features</em> as vari√°veis <em>timepoint</em>, <em>signal</em> e <em>event</em>; e como <em>target</em>, a vari√°vel <em>region</em>. Ou seja, a proposta √© identificar se a medi√ß√£o foi realizada na regi√£o parietal ou frontal do c√©rebro.</p>


## üèãÔ∏è‚Äç‚ôÄÔ∏è Construindo e Treinando a BNN
<p align="justify">Para modificar uma rede neural <strong>regressora</strong> para uma <strong>classificadora bin√°ria</strong> em Python puro, foi necess√°rio realizar algumas altera√ß√µes no c√≥digo dispon√≠vel, como incluindo m√©todos e mudando a avalia√ß√£o de performance do modelo.</p>

### -> Adicionando log 
<p align="justify"> O notebook n√£o apresentava o m√©todo de logaritmo natural na fun√ß√£o <strong>Valor</strong>. Contudo, para conseguir realizar as opera√ß√µes da fun√ß√£o de perda, seria necess√°rio realizar essa opera√ß√£o e, por isso, a implementamos.</p>

### -> Binary Cross Entropy Loss
<p align="justify">Essa √© uma fun√ß√£o de perda bastante utilizada para problemas de classifica√ß√£o bin√°ria. Considerando um conjunto de N exemplos, a perda √© calculada da seguinte forma:</p>

$$
\text{Loss} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right]
$$

<p align="justify">Em que $y_i$ representa o valor real do exemplo <em>i</em> e $p_i$ √© a probabilidade predita para esse exemplo, sendo um n√∫mero entre 0 e 1.<sup>4</sup></p>

### -> Acur√°cia
<p align="justify">Essa foi a m√©trica escolhida para avaliar o desempenho da rede neural de classifica√ß√£o. A acur√°cia indica a raz√£o de previs√µes corretas em rela√ß√£o ao total de amostras dispon√≠veis no conjunto de dados. Ou seja:</p>

$$
\mathrm{ACC = \frac{VP + VN}{VP + FP + VN + FN}}
$$

<p align="justify">Sendo $VP$ o verdadeiro positivo, $FP$ o falso positivo, $VN$ o verdadeiro negativo e $FN$ o falso negativo. Nesse sentido, a acur√°cia √© uma m√©trica que varia entre 0 e 1 e, quanto maior esse valor, melhor o desempenho do modelo.</p>

## üî¢ Resultados Obtidos
<div align="justify">
Os resultados obtidos foram abaixo do esperado. Como foi criada uma rede neural com quatro camadas ocultas e o dataset √© did√°tico, esperava-se um desempenho melhor. No entanto, por ter sido implementado em Python puro, o c√≥digo n√£o √© otimizado, o que ajuda a explicar os resultados pouco melhores aos de um modelo de baseline. Ainda assim, o que foi constru√≠do √© bastante did√°tico e contribui para a compreens√£o de todos os passos realizados por uma <em>Rede Neural Bin√°ria</em> at√© alcan√ßar o <em>target</em>. A acur√°cia do modelo atingiu 55.87%, e a matriz de confus√£o a seguir evidencia que o modelo n√£o apresentou boa sensibilidade aos dados, pois os resultados preditos s√£o semelhantes ao baseline.
</div>

<div align="center">
  <img src="Imagens/matriz_confusao.jpg" alt="Descri√ß√£o da imagem" width="400"/>
</div>


## üòÅ Conclus√£o
<div align="justify">
O notebook √© bastante relevante para compreender como funciona uma <em>Rede Neural Bin√°ria</em> em Python puro, assim como para entender como √© poss√≠vel avaliar a performance desse tipo de modelo. Contudo, <strong>n√£o</strong> √© um c√≥digo otimizado para gerar resultados relevantes em problemas de classifica√ß√£o bin√°ria. Al√©m disso, todos os debates contidos neste README podem ser lidos de maneira mais detalhada no notebook dispon√≠vel.
</div>

## üë©‚Äçü¶≥ Refer√™ncias
$1$ [**GitHub - mwaskom/seaborn-data: Data repository for seaborn examples**](https://github.com/mwaskom/seaborn-data)  
Acesso em 6 de abril de 2025.

$2$ [**‚ÄúAdaptive Engagement of Cognitive Control in Context-Dependent Decision Making | Cerebral Cortex | Oxford Academic‚Äù**](https://academic.oup.com/cercor/article/27/2/1270/3056315?keytype=ref&ijkey=5hjFprzQ7miiYZ4)  
Acesso em 6 de abril de 2025.

$3$ [**‚ÄúClassification of Neural Network in TensorFlow | GeeksforGeeks‚Äù**](https://www.geeksforgeeks.org/classification-of-neural-network-in-tensorflow/)  
Acesso em 6 de abril de 2025.

$4$ [**GeeksforGeeks. ‚ÄúWhat Is Cross-Entropy Loss Function?‚Äù**](https://www.geeksforgeeks.org/what-is-cross-entropy-loss-function/)  
Acesso em 6 de abril de 2025.

$5$ [**Kuriakose, Jeril. ‚ÄúA Simple Neural Network Classifier Using PyTorch, from Scratch‚Äù. Analytics Vidhya (blog)**](https://medium.com/analytics-vidhya/a-simple-neural-network-classifier-using-pytorch-from-scratch-7ebb477422d2)  
Acesso em 6 de abril de 2025.


## üß† Contribui√ß√µes dos Colaboradores
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/172424897?v=4" width=115><br><sub> Maria Emily Nayla</sub>](https://github.com/MEmilyGomes)<br> [<sub>Curr√≠culo Lattes</sub>](http://lattes.cnpq.br/9482558334105708)<br> |  [<img loading="lazy" src="https://avatars.githubusercontent.com/u/172425104?v=4" width=115><br><sub>Thomas Wolff Hannemann</sub>](https://github.com/ThomasHannemann)<br> <br> | 
| :---: | :---: | 

#### Para o Projeto:
* Emily Gomes: Atualizando, treinando e analisando dados da previs√£o de uma BNN utilizando Python puro.
* Thomas Wolff: Atualizando, treinando e analisando dados da previs√£o de uma BNN utilizando Python puro. 

#### Para o Reposit√≥rio GitHub:
* Emily Gomes: README, upload de imagens.
* Thomas Wolff: Upload do notebook Jupyter referente a constru√ß√£o, treinamento e previs√£o da BNN.
  
